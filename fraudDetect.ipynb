{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "563e738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0501ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe6e7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve,f1_score, precision_score,recall_score,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286aacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4ed8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2969c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Class\n",
      "0    282517\n",
      "1       465\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('fraud_detection.db')\n",
    "#when only query, no need cursor.   cursor = conn.cursor()\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * FROM transactions \n",
    "WHERE Amount > 0\n",
    "\"\"\"\n",
    "data = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(data.head())\n",
    "# This code connects to a SQLite database, reads a CSV file into a DataFrame,\n",
    "# and executes a SQL query to retrieve transactions with a positive amount.\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b12f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Number of outliners: 31661\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum()) #check for null values\n",
    "data['Class'] = data['Class'].astype('int') #make sure Class is int\n",
    "\n",
    "Q1 = data['Amount'].quantile(0.25)\n",
    "Q3 = data['Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliners = data[(data['Amount'] < (Q1 - 1.5 * IQR)) | (data['Amount'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliners: {len(outliners)}\") # check for outliners in Amount column\n",
    "# these outliners may be frauds, so we will keep them for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "441a3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler.pkl saved！\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V25       V26       V27       V28  Amount  \\\n",
      "0  0.098698  0.363787  ...  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1  0.085102 -0.255425  ...  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2  0.247676 -1.514654  ... -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3  0.377436 -1.387024  ...  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4 -0.270533  0.817739  ... -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "\n",
      "   Class  Hour  Is_Night  Amount_Scaled  Amount_high  \n",
      "0      0   0.0         1       0.242005            0  \n",
      "1      0   0.0         1      -0.343785            0  \n",
      "2      0   0.0         1       1.155155            1  \n",
      "3      0   0.0         1       0.137868            0  \n",
      "4      0   0.0         1      -0.075469            0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert Time to Hour and create Is_Night feature\n",
    "data['Hour'] = data['Time'] // 3600 % 24  # Convert Time to Hour (0-23)\n",
    "data['Is_Night'] = data['Hour'].apply(lambda x: 1 if 0<= x <= 6 else 0)\n",
    "\n",
    "# Amount feature engineering, scaling and binning for better model performance\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# standardize the Amount feature\n",
    "data['Amount_Scaled'] = scaler.fit_transform(data[['Amount']])\n",
    "data['Amount_high'] = data['Amount'].apply(lambda x: 1 if x > 300 else 0)\n",
    "# save scaler.pkl\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"scaler.pkl saved！\")\n",
    "\n",
    "print(data.head(5))  # Display summary statistics of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62441f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampled class distribution:\n",
      "Class\n",
      "0    282517\n",
      "1    282517\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Resampling using SMOTE, to handle class imbalance, improve model performance,\n",
    "# and ensure the model is not biased towards the majority class\n",
    "# but may increase the risk of overfitting, need to compare with scale_pos_weight\n",
    "x = data.drop(['Class', 'Time'], axis=1)\n",
    "y = data['Class']\n",
    "smote = SMOTE(random_state=42)\n",
    "x_resampled, y_resampled = smote.fit_resample(x, y)\n",
    "print(f\"resampled class distribution:\\n{y_resampled.value_counts()}\")\n",
    "x_resampled.to_csv('x_resampled.csv', index=False)\n",
    "y_resampled.to_csv('y_resampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf0c98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE训练集形状： (452027, 33)\n",
      "SMOTE测试集形状： (113007, 33)\n",
      "\n",
      "solution1：SMOTE（default） - report：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56412\n",
      "           1       1.00      1.00      1.00     56595\n",
      "\n",
      "    accuracy                           1.00    113007\n",
      "   macro avg       1.00      1.00      1.00    113007\n",
      "weighted avg       1.00      1.00      1.00    113007\n",
      "\n",
      "solution1 AUC-ROC: 0.9999944350080449\n",
      "SMOTE train F1： 0.9999977868516858\n",
      "SMOTE test F1： 0.9998321688205002\n"
     ]
    }
   ],
   "source": [
    "# 1. load smote data\n",
    "X = pd.read_csv('x_resampled.csv')\n",
    "y = pd.read_csv('y_resampled.csv').values.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"SMOTE训练集形状：\", X_train.shape)\n",
    "print(\"SMOTE测试集形状：\", X_test.shape)\n",
    "\n",
    "# 2. smote model training and evaluation\n",
    "model_smote = XGBClassifier(random_state=42)  # default：n_estimators=100, max_depth=6, learning_rate=0.3\n",
    "model_smote.fit(X_train, y_train)\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "print(\"\\nsolution1：SMOTE（default） - report：\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "print(f\"solution1 AUC-ROC: {roc_auc_score(y_test, model_smote.predict_proba(X_test)[:, 1])}\")\n",
    "# check if overfitting\n",
    "print(\"SMOTE train F1：\", f1_score(y_train, model_smote.predict(X_train)))\n",
    "print(\"SMOTE test F1：\", f1_score(y_test, y_pred_smote))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef9389a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "solution2：scale_pos_weight（default） - report：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.83      0.90        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.91      0.95     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "solution2 AUC-ROC: 0.982696989882053\n",
      "scale_pos_weight train F1： 1.0\n",
      "scale_pos_weight test F1： 0.9\n"
     ]
    }
   ],
   "source": [
    "# 3. solution2 original data + scale_pos_weight\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data['Hour'] = (data['Time'] // 3600) % 24\n",
    "data['Is_Night'] = data['Hour'].apply(lambda x: 1 if 0 <= x <= 6 else 0)\n",
    "data['Amount_Scaled'] = StandardScaler().fit_transform(data[['Amount']])\n",
    "data['Amount_high'] = data['Amount_Scaled'].apply(lambda x: 1 if x > 500 else 0)\n",
    "X_orig = data.drop(['Class', 'Time'], axis=1)\n",
    "y_orig = data['Class']\n",
    "\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_orig, y_orig, test_size=0.2, random_state=42)\n",
    "fraud_ratio = len(y_train_orig[y_train_orig == 0]) / len(y_train_orig[y_train_orig == 1])\n",
    "model_spw = XGBClassifier(scale_pos_weight=2*fraud_ratio, random_state=42)  # 增大权重\n",
    "model_spw.fit(X_train_orig, y_train_orig)\n",
    "y_pred_spw = model_spw.predict(X_test_orig)\n",
    "print(\"\\nsolution2：scale_pos_weight（default） - report：\")\n",
    "print(classification_report(y_test_orig, y_pred_spw))\n",
    "print(f\"solution2 AUC-ROC: {roc_auc_score(y_test_orig, model_spw.predict_proba(X_test_orig)[:, 1])}\")\n",
    "# check if overfitting\n",
    "print(\"scale_pos_weight train F1：\", f1_score(y_train_orig, model_spw.predict(X_train_orig)))\n",
    "print(\"scale_pos_weight test F1：\", f1_score(y_test_orig, y_pred_spw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6e8c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEST prarmater（SMOTE，optimize recall）： {'learning_rate': np.float64(0.2911852430188321), 'max_depth': 5, 'n_estimators': 150}\n",
      "Best Recall score： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 4. optimize （RandomizedSearchCV，optimize recall）\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': uniform(0.01, 0.3),  # use uniform distribution\n",
    "}\n",
    "random_search = RandomizedSearchCV(XGBClassifier(random_state=42), param_grid, n_iter=20, cv=5, scoring='recall', n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"\\nBEST prarmater（SMOTE，optimize recall）：\", random_search.best_params_)\n",
    "print(\"Best Recall score：\", random_search.best_score_)\n",
    "model_best = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c36d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "optimized model（SMOTE，threshold 0.3） - report：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56412\n",
      "           1       1.00      1.00      1.00     56595\n",
      "\n",
      "    accuracy                           1.00    113007\n",
      "   macro avg       1.00      1.00      1.00    113007\n",
      "weighted avg       1.00      1.00      1.00    113007\n",
      "\n",
      "optimized AUC-ROC: 0.9999956117781676\n",
      "Optimized train F1： 1.0\n",
      "Optimized test F1： 0.9998056743101438\n"
     ]
    }
   ],
   "source": [
    "# evaluate model（modify threshold to 0.3）defaule threshhold 0.5\n",
    "# y_pred = model_best.predict(X_test)   \n",
    "y_pred_best = (model_best.predict_proba(X_test)[:, 1] > 0.3).astype(int)\n",
    "print(\"\\noptimized model（SMOTE，threshold 0.3） - report：\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(f\"optimized AUC-ROC: {roc_auc_score(y_test, model_best.predict_proba(X_test)[:, 1])}\")\n",
    "# 检查过拟合\n",
    "print(\"Optimized train F1：\", f1_score(y_train, model_best.predict(X_train)))\n",
    "print(\"Optimized test F1：\", f1_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "478fa05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 importance：\n",
      "V14       0.626879\n",
      "V4        0.054536\n",
      "V12       0.038433\n",
      "V8        0.024459\n",
      "V1        0.023954\n",
      "V10       0.020700\n",
      "V17       0.018914\n",
      "V3        0.017613\n",
      "Amount    0.015633\n",
      "V11       0.013697\n",
      "dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liuji\\AppData\\Local\\Temp\\ipykernel_18488\\3385652392.py:8: UserWarning: Glyph 65288 (\\N{FULLWIDTH LEFT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance.png')\n",
      "C:\\Users\\Liuji\\AppData\\Local\\Temp\\ipykernel_18488\\3385652392.py:8: UserWarning: Glyph 65289 (\\N{FULLWIDTH RIGHT PARENTHESIS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance.png')\n"
     ]
    }
   ],
   "source": [
    "# 5. feature importance\n",
    "importance = pd.Series(model_best.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance[:10].plot(kind='bar')\n",
    "plt.title('feature importance（XGBoost - SMOTE optimized）')\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('importance')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "pd.DataFrame({'Feature': X_train.columns, 'Importance': model_best.feature_importances_}).to_csv('feature_importance.csv', index=False)\n",
    "print(\"\\nTop 10 importance：\")\n",
    "print(importance[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bca0313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. model save（base recall）\n",
    "final_model = model_best\n",
    "#X_final, y_final, X_test_final, y_test_final = X, y, X_test, y_test\n",
    "joblib.dump(final_model, 'fraud_model.pkl')\n",
    "\n",
    "# 7. export（for Power BI）\n",
    "# fpr, tpr, thresholds = roc_curve(y_test_final, final_model.predict_proba(X_test_final)[:, 1])\n",
    "# roc_data = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Thresholds': thresholds})\n",
    "# roc_data.to_csv('roc_data.csv', index=False)\n",
    "# results = X_test_final.copy()\n",
    "# results['Actual'] = y_test_final\n",
    "# results['Predicted'] = (final_model.predict_proba(X_test_final)[:, 1] > 0.3).astype(int)\n",
    "# results['Fraud_Probability'] = final_model.predict_proba(X_test_final)[:, 1]\n",
    "# results.to_csv('model_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
